{"cells":[{"cell_type":"markdown","metadata":{"id":"jVGOHFL3W5hp"},"source":["## **LATAM Challenge - Data Ingest, Storage and Processing with Google Drive, Google Cloud Storage and Google BigQuery in Google Colab (Jupyter) with Python 3.10**\n","\n","**Welcome to the Data Engineer Challenge.** On this occasion, you will have the opportunity to get closer to the reality of the role, demonstrate your skills and knowledge in data processing with Python and different data structures.\n","\n","**Preparation:**\n","\n","1. Initial project commit (done with GitHub desktop)\n","2. Install Git Flow with `brew install git-flow`\n","3. Configure the repository with `git flow init`\n","4. Configure feature finishes to be done only in develop with `git config gitflow.feature.finish.keepremote true`\n","5. Configure releases to not directly merge on main with `git config gitflow.feature.finish.keepremote=true`\n","6. Synchronize the repository with GDrive\n","7. Read the code from GDrive with Colab\n","\n","**Additional Notes:**\n","\n","* The `README.md` file mentions using GitHub Desktop, Git Flow, and Colab. These are tools that can be used for version control and code collaboration.\n","* The `README.md` file also mentions measuring time and memory. This can be done using Python's built-in `time` and `memory_profiler` modules.\n","* English was used for both documentation and code."]},{"cell_type":"markdown","metadata":{"id":"e0ytAOoEE50a"},"source":["## **Challenge Guidelines:**\n","\n","**Repository:**\n","\n","* Your solution must be in a public repository on the GitHub platform.\n","\n","**Submitting your challenge:**\n","\n","1. Make a POST request to [https://advana-challenge-check-api-cr-k4hdbggvoq-uc.a.run.app/data-engineer](https://advana-challenge-check-api-cr-k4hdbggvoq-uc.a.run.app/data-engineer).\n","2. The request body should be a JSON object with the following fields:\n","    * `name`: Your full name\n","    * `mail`: Your email address\n","    * `github_url`: The URL of your GitHub repository containing the solution\n","\n","**Deadline:**\n","\n","* The deadline for submitting the challenge is 5 calendar days after receiving the challenge.\n","\n","**Technology and Techniques:**\n","\n","* You can use any technology or technique you prefer for data processing.\n","* We will value your knowledge of cloud platforms.\n","* If you use cloud platforms, follow the steps in your files WITHOUT adding access credentials to the different services.\n","\n","**Ranking Criteria:**\n","\n","* Challenges that are clearly organized, explanatory, modular, efficient, and creative will be ranked higher.\n","\n","**Assumptions and Documentation:**\n","\n","* Write down the assumptions you are making.\n","* Include the versions of the libraries you are using in the requirements.txt file.\n","* Do not delete what is already written in the requirements.txt file.\n","* For this challenge, we recommend that you clearly describe how each part of your exercise can be improved.\n","\n","**Data:**\n","\n","* You must use the data contained in the provided file.\n","* You can use the official Twitter documentation to understand the data structure.\n","\n","**Git Usage:**\n","\n","* We will positively evaluate good practices of Git usage.\n","* Use the main branch for any final version you want us to review.\n","* We recommend that you use some GitFlow practice.\n","* Do not delete your development branches.\n","\n","**Error Handling and Edge Cases:**\n","\n","* Consider error handling and edge cases.\n","\n","**Maintainability, Readability, and Scalability:**\n","\n","* Remember that you will be working with other developers, so the maintainability, readability, and scalability of your code is essential.\n","\n","**Code Documentation:**\n","\n","* Good code documentation always helps the reader.\n","\n","**Additional Notes:**\n","\n","* The `README.md` file mentions using GitHub Desktop, Git Flow, and Colab. These are tools that can be used for version control and code collaboration.\n","* The `README.md` file also mentions measuring time and memory. This can be done using Python's built-in `time` and `memory_profiler` modules.\n","* `# type: ignore` was used for thois libraries that exists within the google colab environment by default and they are not required in the `requirements.txt` file"]},{"cell_type":"markdown","source":["# **Beginning of Challenge Code**"],"metadata":{"id":"wyhhTnA4_BXo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"R45EuZ1JWSa4","executionInfo":{"status":"ok","timestamp":1712459957887,"user_tz":240,"elapsed":331,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f5f99fcb-75fa-4290-84ee-264348803807"},"outputs":[{"output_type":"stream","name":"stdout","text":["All initial libraries were imported\n"]}],"source":["# Conditionally delete the 'end_time' variable for potential measurement purposes\n","try:\n","    del end_time  # For measurement if the notebook runs all the code snippets\n","except NameError:\n","    pass  # Variable doesn't exist, so no need to delete\n","\n","# Declare the 'end_time' variable as a float\n","end_time: float = None\n","\n","# Import the 'sys' library for interacting with the interpreter\n","import sys\n","\n","# Exit the script if it's not the main program (avoids unintended execution as a module)\n","if __name__ != \"__main__\":\n","    sys.exit()\n","\n","# Import general-purpose libraries:\n","import logging  # For logging messages\n","import os  # For interacting with the operating system\n","import time  # For working with time-related functions\n","\n","# Import type-related libraries:\n","from typing import List, Tuple, Any, Optional  # For type annotations\n","import datetime  # For working with dates and times\n","\n","# Import I/O-related libraries:\n","import io  # For common I/O operations\n","\n","# Import Google Colab-specific libraries:\n","from google.colab import drive  # For interacting with Google Drive\n","\n","# Print a message indicating successful library imports\n","print(\"All initial libraries were imported\")\n"]},{"cell_type":"markdown","metadata":{"id":"hfr4Y-Cv8Cd9"},"source":["## **Definitions and Configurations:**\n","The following code snippet defines constants used in the data transfer and processing pipeline:\n","\n","- **Google Cloud Storage (GCS) Information:**\n","    - `BUCKET_NAME`: Specifies the name of the GCS bucket where data will be uploaded (`tw-gcp-public-lab`).\n","    - `FOLDER_NAME`: Denotes the folder within the bucket to store the uploaded file (`raw`).\n","    - `ZIP_FILE_NAME`: Represents the name of the compressed file containing tweets data (`tweets.json.zip`).\n","    - `GCS_SOURCE_URI`: Constructs the full URI for the file location in GCS after upload (`gs://tw-gcp-public-lab/raw/`).\n","\n","- **Local File Paths:**\n","    - `SOURCE_PATH`: Currently defines a local file path (`/content/drive/Othercomputers/My Mac/latam-challenge`), but it's not used in the provided code for downloading.\n","\n","- **Google Cloud Project and Dataset Information:**\n","    - `PROJECT_ID`: Specifies the Google Cloud project ID (`tw-techdash`).\n","    - `DATASET_NAME`: Defines the name of the BigQuery dataset where the data will be loaded (`tweets_dataset`).\n","    - `TABLE_NAME`: Identifies the name of the BigQuery table to store the extracted tweets data (`tweets`).\n","\n","**Observations:**\n","\n","- The `SOURCE_PATH` might require modification if you intend to download a file from a different location.\n","- Consider using environment variables or a configuration file to manage these constants, making your code more flexible and easier to maintain."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g57ic23AMKFp","executionInfo":{"status":"ok","timestamp":1712459958277,"user_tz":240,"elapsed":4,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0ddbdf24-ae67-4969-8d97-83aa4ac4bf1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["--------- Local Variables ---------\n","LC_START_TIME: 1712459958.0463662\n","LC_BUCKET_NAME: tw-gcp-public-lab\n","LC_FOLDER_NAME: raw\n","LC_ZIP_FILE_NAME: tweets.json.zip\n","LC_FILE_ID: 1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis\n","LC_GCS_SOURCE_URI: gs://tw-gcp-public-lab/raw/\n","LC_MOUNT_POINT: /content/drive\n","LC_SOURCE_PATH: /content/drive/Othercomputers/My Mac/latam-challenge\n","LC_PROJECT_ID: tw-techdash\n","LC_DATASET_NAME: tweets_dataset\n","LC_TABLE_NAME: tweets\n","LC_LOGGING_LEVEL: 10\n","LC_LOGGING_FILE: /content/drive/Othercomputers/My Mac/latam-challenge/latam-challenge.log\n"," ----------------------------------\n","Definitions and Configurations initialized\n"]}],"source":["# Definitions\n","\n","# Notebook time measure (consider using a timer library for better accuracy)\n","START_TIME = os.environ['LC_START_TIME'] = str(time.time())\n","\n","# Google Cloud Storage (GCS) information\n","# Assumption: All environment variables are str type\n","BUCKET_NAME = os.environ['LC_BUCKET_NAME'] = \"tw-gcp-public-lab\"\n","FOLDER_NAME = os.environ['LC_FOLDER_NAME'] = \"raw\"\n","ZIP_FILE_NAME = os.environ['LC_ZIP_FILE_NAME'] = \"tweets.json.zip\"\n","FILE_ID = os.environ['LC_FILE_ID'] = \"1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis\"\n","GCS_SOURCE_URI = os.environ['LC_GCS_SOURCE_URI'] = f\"gs://{BUCKET_NAME}/{FOLDER_NAME}/\"\n","\n","# Local file paths (consider user input/environment variables for flexibility)\n","MOUNT_POINT = os.environ['LC_MOUNT_POINT'] = \"/content/drive\"\n","SOURCE_PATH = os.environ['LC_SOURCE_PATH'] = \"/content/drive/Othercomputers/My Mac/latam-challenge\"\n","\n","# Google Cloud project and dataset information (consider environment variables for better management)\n","PROJECT_ID = os.environ['LC_PROJECT_ID'] = \"tw-techdash\"\n","DATASET_NAME = os.environ['LC_DATASET_NAME'] = \"tweets_dataset\"\n","TABLE_NAME = os.environ['LC_TABLE_NAME'] = \"tweets\"\n","\n","# Logging\n","LOGGING_LEVEL = os.environ['LC_LOGGING_LEVEL'] = str(logging.DEBUG)\n","LOGGING_FILE = os.environ['LC_LOGGING_FILE'] = f\"{SOURCE_PATH}/latam-challenge.log\"\n","\n","# Configurations\n","\n","# Logging configuration\n","logging.basicConfig(filename=LOGGING_FILE, level=int(LOGGING_LEVEL))\n","\n","\n","def print_local_variables():\n","    \"\"\"\n","    Prints environment variables that begin with \"LC_\".\n","\n","    These variables often control language and locale-related settings.\n","\n","    Args:\n","        None\n","    \"\"\"\n","    variables_blacklist = ['LC_ALL']\n","\n","    print(\"--------- Local Variables ---------\")\n","    for key, value in os.environ.items():\n","        if key.startswith(\"LC_\") and (key not in variables_blacklist):\n","            print(f\"{key}: {value}\")\n","    print(\" ----------------------------------\")\n","\n","\n","print_local_variables()\n","print(\"Definitions and Configurations initialized\")\n"]},{"cell_type":"markdown","metadata":{"id":"n0zd65ksIbea"},"source":["## **Jupyter Kernel code reloading**\n","\n","**Functionality:**\n","\n","* This code snippet utilizes magic commands within Jupyter Notebooks to manage code reloading.\n","* The `%reload_ext autoreload` line imports and activates the `autoreload` extension.\n","* The `%autoreload 2` line configures the `autoreload` extension to automatically reload Python modules when changes are detected.\n","\n","**Key Concepts:**\n","\n","* **Jupyter Magic Commands:** `%` prefix is used for magic commands that provide special functionality within Jupyter notebooks.\n","* **Autoreload Extension:**  A Jupyter extension that automatically reloads Python modules when changes are detected in the corresponding source files.\n","* **Reload Level:** The level `2` specifies that reload should occur when source files or any imported modules are modified (level 1 only reloads source file changes).\n","\n","**Overall Assessment:**\n","\n","* This code improves development efficiency within Jupyter notebooks by automatically reloading code, avoiding manual restarts.\n","* It leverages the `autoreload` extension for automatic reloading functionality.\n","* The configuration level `2` ensures comprehensive reloading behavior.\n","\n","**Potential Enhancements:**\n","\n","* While automatic reloading is helpful in development, it might not be suitable for production environments due to potential unexpected behavior during execution.\n","* Consider using this approach primarily for interactive development within Jupyter notebooks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkniVfT9W5hr","executionInfo":{"status":"ok","timestamp":1712459958277,"user_tz":240,"elapsed":3,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"41689ca6-694a-4b03-eb12-17cee7ca167a"},"outputs":[{"output_type":"stream","name":"stdout","text":["IPython autoreload activated\n"]}],"source":["# Enable automatic reloading of modules in Jupyter Notebook (improves development workflow)\n","%reload_ext autoreload\n","\n","# Automatically restart the kernel whenever the source code changes\n","# (Provides a clean development environment)\n","%autoreload 2\n","\n","print(\"IPython autoreload activated\")\n"]},{"cell_type":"markdown","metadata":{"id":"KcY78DdKJ1V_"},"source":["## **Google Drive mounting**\n","\n","**Functionality:**\n","\n","1. **Connects Google Drive:** This code establishes a connection between your Google Drive storage and the virtual machine running the Colab notebook.\n","2. **Navigates to Project Directory:** This magic command changes the working directory within the Colab notebook to a specific location within your project directory.\n","\n","**Key Concepts:**\n","\n","* **Google Drive Mounting:**\n","    - `from google.colab import drive`: Imports the `drive` module for interacting with Google Drive from Colab.\n","    - `drive.mount('/content/drive', force_remount=True)`: Mounts your Drive at the `/content/drive` path within Colab.\n","    - **Authorization:** Requires initial authorization to grant Colab access to your Drive.\n","* **Jupyter Notebook Magic Commands:**\n","    - `%cd`: A magic command specifically designed for changing directories.\n","\n","**Overall Assessment:**\n","\n","* **Convenient Data Access:** Enables seamless access to your personal data stored in Google Drive for use within Colab notebooks.\n","* **Improved Code Organization:** Helps organize your notebook within the project structure by focusing on a specific subdirectory (like \"src\").\n","\n","**Potential Enhancements:**\n","\n","* **Google Drive Mounting:**\n","    - **Error Handling:** Consider incorporating `try-except` blocks to gracefully handle potential mounting issues.\n","    - **Authentication Persistence:** Explore ways to persist the authentication token (if applicable) to avoid re-authorization for every session.\n","* **Navigation:**\n","    - **Clear Path Definitions:** Replace `{SOURCE_PATH}` with the actual path to your project directory for clarity.\n","    - **Error Handling:** Consider handling potential issues like non-existent directories using Python code (like `try-except` blocks).\n","\n","**Explanation:**\n","\n","1. **Mount Google Drive:** The first part of the code imports the `drive` module and mounts your Google Drive to the `/content/drive` directory within Colab. This allows you to access your Drive files from within your notebook.\n","2. **Change Directory:** The `%cd {SOURCE_PATH}/src` line uses a magic command to navigate to the subdirectory named \"src\" within your project directory (assuming `{SOURCE_PATH}` points to the correct location). This helps organize your notebook by focusing on the relevant project code.\n","\n","**Important Notes:**\n","\n","* Replace `{SOURCE_PATH}` with the actual path to your project directory on your machine.\n","* You'll need to go through an authorization process the first time you run the mounting code to grant Colab access to your Drive.\n","* It was not possible to have this"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IV-79dMCpYAh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712459961447,"user_tz":240,"elapsed":3172,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"fc86813a-5f2a-41ae-ed7c-8b87c58b39a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Changed directory to: /content/drive/Othercomputers/My Mac/latam-challenge/src\n"]}],"source":["# Mount Google Drive (optional, depending on usage context)\n","# Uncomment the following line if mounting is needed:\n","drive.mount(MOUNT_POINT, force_remount=True)\n","\n","# Change directory using a more explicit method\n","target_directory = os.path.join(MOUNT_POINT, SOURCE_PATH, \"src\")\n","logging.info(f\"Changing directory to: {target_directory}\")\n","os.chdir(target_directory)\n","\n","# Confirm the current directory:\n","print(f\"Changed directory to: {os.getcwd()}\")  # Use os.getcwd() for accuracy\n"]},{"cell_type":"markdown","metadata":{"id":"KuUJyVVpKQjJ"},"source":["## **Libraries requirements and imports**\n","\n","**Functionality:**\n","\n","- **Installs Python Libraries:** This code snippet installs a collection of Python libraries listed in a file named `requirements.txt` within the currently active virtual environment.\n","\n","**Key Concepts:**\n","\n","- **requirements.txt File:** This text file contains a list of library names and their version requirements, ensuring consistent installation across environments.\n","- **Virtual Environments:** Virtual environments isolate project dependencies, preventing conflicts with other Python projects on your system.\n","- **sys.executable:** This Python variable points to the path of the Python interpreter for the active virtual environment.\n","- **pip:** The Python Package Installer (pip) is used for managing Python packages and libraries.\n","\n","**Explanation:**\n","\n","1. **`import sys`**: Imports the `sys` module, providing access to system-specific variables and functions.\n","2. **`!{sys.executable} -m pip install -r '../requirements.txt'`**: This line calls the pip installer within the virtual environment:\n","   - **`!`**: Jupyter Notebook magic command to execute terminal commands.\n","   - **`{sys.executable}`**: Ensures pip is called from the virtual environment's Python interpreter.\n","   - **`-m`**: Designates a module to execute as a script (in this case, `pip`).\n","   - **`install -r`**: Instructs pip to install packages from a requirements file.\n","   - **`'../requirements.txt'`**: Specifies the path to the requirements file (relative to the current notebook's directory).\n","\n","**Important Notes:**\n","\n","- **Virtual Environment Activation:** Ensure you've activated the desired virtual environment before running this code.\n","- **Path to requirements.txt:** Verify that `../requirements.txt` correctly points to the file's location.\n","- **Internet Connection:** An internet connection is required for pip to download and install packages.\n","\n","**Overall Assessment:**\n","\n","- **Efficient Dependency Management:** Using `requirements.txt` is a best practice for managing project dependencies consistently.\n","- **Consistent Environments:** Facilitates consistent library installations across different machines for reproducibility.\n","- **Collaboration:** Enables easy setup of the same project environment for others.\n","\n","**Potential Enhancements:**\n","\n","- **Error Handling:** Consider incorporating error handling (like try-except blocks) to gracefully handle potential issues during installation, such as network connectivity problems or missing packages.\n"]},{"cell_type":"code","source":["%run libraries.py\n","\n","install_requirements\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"2SS1z03vnz0d","executionInfo":{"status":"ok","timestamp":1712459961447,"user_tz":240,"elapsed":3,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"d0b25908-8872-4429-9682-9e7182f857fc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.install_requirements(requirements_path: str = '../requirements.txt') -> None>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>install_requirements</b><br/>def install_requirements(requirements_path: str=&#x27;../requirements.txt&#x27;) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/libraries.py</a>Installs Python libraries from the specified requirements file.\n","\n","Args:\n","    requirements_path (str, optional): Path to the requirements.txt file.\n","\n","Returns:\n","    None</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 34);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["check_requirements\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"uOo19Sy1_fWk","executionInfo":{"status":"ok","timestamp":1712459961447,"user_tz":240,"elapsed":2,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"c588fc0c-8eb8-4777-e629-a1fcf447c09e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.check_requirements(requirements_path: str = '../requirements.txt') -> bool>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>check_requirements</b><br/>def check_requirements(requirements_path: str=&#x27;../requirements.txt&#x27;) -&gt; bool</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/libraries.py</a>Checks if the required libraries are already installed.\n","\n","Args:\n","    requirements_path (str, optional): Path to the requirements.txt file.\n","\n","Returns:\n","    bool: True if all required libraries are installed, False otherwise.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 4);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V_d7gErJW5hs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712459968297,"user_tz":240,"elapsed":6852,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"afc4ebe9-9a8f-47f5-cbb5-c30cecbbe02c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully installed libraries from requirements.txt\n"]}],"source":["# Call the install_requirements function\n","install_requirements()\n","\n","# Assumption: install_requirements() is defined in the codebase.\n","# Improvement: If install_requirements() has a meaningful return value, use it for further actions (e.g., download data if installation is successful).\n"]},{"cell_type":"code","source":["# Import project libraries\n","%run common.py  # Assuming common functions reside here\n","%run measure.py  # Assuming profiling functions reside here (consider alternatives)\n","\n","# Google Cloud Platform libraries\n","from google.cloud import storage  # For interacting with Google Cloud Storage\n","from google.cloud import bigquery  # For interacting with BigQuery\n","\n","# Profilers (consider alternative profiling tools)\n","# type: ignore  # Ignoring potential type hinting issues for profilers\n","from line_profiler import LineProfiler  # For line-by-line profiling\n","from memory_profiler import memory_usage  # For memory usage profiling\n","\n","extract_zip_file_conditionally # common.py\n"],"metadata":{"id":"3-fOVIZbioi5","executionInfo":{"status":"ok","timestamp":1712459968297,"user_tz":240,"elapsed":7,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"19762d98-5bb5-4c22-f9ff-71fbbcbcd6d9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.extract_zip_file_conditionally(bucket: google.cloud.storage.bucket.Bucket, folder_name: str, zip_file_name: str) -> str>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>extract_zip_file_conditionally</b><br/>def extract_zip_file_conditionally(bucket: storage.Bucket, folder_name: str, zip_file_name: str) -&gt; str</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/common.py</a>Extracts a ZIP file in Google Cloud Storage conditionally.\n","\n","Checks if the ZIP file exists and is identical to the local version before\n","extracting its contents to avoid redundant operations.\n","\n","Args:\n","    bucket (storage.Bucket): The Google Cloud Storage bucket object.\n","    folder_name (str): The name of the folder containing the ZIP file.\n","    zip_file_name (str): The name of the ZIP file to extract.\n","\n","Returns:\n","    str: The name of the extracted JSON file, or an empty string if no\n","          extraction occurred.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 6);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["dummy_function # common.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"OaYAQqjjWVTI","executionInfo":{"status":"ok","timestamp":1712459968297,"user_tz":240,"elapsed":6,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"20501086-790d-41a7-bc41-ae267c577b98"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.dummy_function() -> None>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>dummy_function</b><br/>def dummy_function() -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/common.py</a>This function intentionally does not perform any actions. \n","It is for testing purposes only on Google Colab.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 70);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["measure_notebook_elapsed_time # measure.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"WL6UHNVLAUVF","executionInfo":{"status":"ok","timestamp":1712459968297,"user_tz":240,"elapsed":6,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"f0793a97-d57d-4895-d3f2-a3c861be9fbd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.measure_notebook_elapsed_time(start_time: float) -> float>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>measure_notebook_elapsed_time</b><br/>def measure_notebook_elapsed_time(start_time: float) -&gt; float</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/measure.py</a>Calculates the elapsed time since the provided start time.\n","\n","Args:\n","    start_time (float): The start time captured previously using time.time().\n","\n","Returns:\n","    float: The elapsed time in seconds.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 3);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["print_notebook_elapsed_time # measure.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"xxqSNxc5AUXN","executionInfo":{"status":"ok","timestamp":1712459968297,"user_tz":240,"elapsed":6,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"a55b607c-892e-4c37-b402-c8b8680192df"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.print_notebook_elapsed_time(elapsed_time: float) -> None>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>print_notebook_elapsed_time</b><br/>def print_notebook_elapsed_time(elapsed_time: float) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/measure.py</a>Prints the elapsed time in a user-friendly format (seconds, minutes, or hours).\n","\n","Args:\n","    elapsed_time (float): The elapsed time in seconds.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 17);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"PA2wPhkO7khO"},"source":["## **Ingest Google Drive ZIP into Google Storage**\n","**Key Functions:**\n","\n","1. **authenticate_google_drive()**: Authenticates with Google Drive using the user's credentials.\n","2. **download_file_from_drive(drive_service, file_id)**: Downloads a specified file from Google Drive.\n","3. **upload_file_to_cloud_storage(client, bucket_name, folder_name, downloaded, zip_file_name)**: Uploads a file to Google Cloud Storage, handling folder creation if needed.\n","4. **decompress_zip_file(client, bucket_name, folder_name, zip_file_name)**: Decompresses a ZIP file within a GCS bucket.\n","\n","**Code Structure:**\n","\n","- **Logging:** Employs `logging` for debugging and tracking progress.\n","- **Error Handling:** Uses try-except blocks to gracefully handle potential errors.\n","- **Modularity:** Separates functionality into distinct, reusable functions.\n","- **Type Hints:** Enhances code readability and potential type checking.\n","\n","**Main Code Execution:**\n","\n","1. Configures logging to a file named 'transfer.log'.\n","2. Authenticates with Google Drive.\n","3. Downloads the specified file from Drive.\n","4. Creates a Cloud Storage client.\n","5. Uploads the downloaded file to GCS.\n","6. Decompresses the ZIP file in GCS if its content type is 'application/zip'.\n","7. Logs success or failure messages.\n","8. Finally, ensures the downloaded file is closed.\n","\n","**Overall Assessment:**\n","\n","- **Well-structured:** The code is organized, modular, and includes error handling.\n","- **Clear Functionality:** It effectively handles file transfer and decompression tasks.\n","- **Authentication Flexibility:** Uses authentication methods external to the code (useful for avoiding credentials in code).\n","- **Good Practices:** Adheres to good practices like logging and try-except blocks.\n","\n","**Potential Enhancements:**\n","\n","- **Parameterization:** Explore using command-line arguments or configuration files to adjust parameters more flexibly.\n","- **Progress Reporting:** Consider more granular progress reporting for downloads/uploads.\n","- **Content Validation:** Validate file content after decompression for integrity.\n","- **Advanced Error Handling:** Implement retries or alternative actions for potential errors.\n","\n","This code provides a foundation for file transfer and decompression tasks within Google Cloud environments, demonstrating clarity and attention to best practices."]},{"cell_type":"code","source":["%run ingest.py\n","\n","upload_drive_file_to_cloud_storage # ingest.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"nObA69j8mp5W","executionInfo":{"status":"ok","timestamp":1712459968685,"user_tz":240,"elapsed":393,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"41d2fb8a-7766-4818-8230-1d56d34a94d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.upload_drive_file_to_cloud_storage(bucket: google.cloud.storage.bucket.Bucket, folder_name: str, downloaded: _io.BytesIO, zip_file_name: str) -> google.cloud.storage.blob.Blob>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>upload_drive_file_to_cloud_storage</b><br/>def upload_drive_file_to_cloud_storage(bucket: storage.Bucket, folder_name: str, downloaded: io.BytesIO, zip_file_name: str) -&gt; storage.Blob</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/ingest.py</a>Uploads a file to Google Cloud Storage.\n","\n","This function uploads a file provided as a BytesIO object to a specified folder\n","within a Google Cloud Storage bucket with a conditional check.\n","\n","Args:\n","    bucket (storage.Bucket): The Google Cloud Storage bucket where the file will be uploaded.\n","    folder_name (str): The name of the folder within the bucket to upload the file to.\n","    downloaded (io.BytesIO): The BytesIO object containing the file data to upload.\n","    zip_file_name (str): The name of the file to be uploaded.\n","\n","Returns:\n","    storage.Blob: The uploaded blob object representing the uploaded file in Cloud Storage.\n","\n","Assumptions:\n","    - The user has authenticated with Google Cloud and has permission to access and write to the specified bucket.\n","    - The `downloaded` object is a valid BytesIO object containing the file data.\n","\n","Suggestions for Improvement:\n","    - Error Handling: Implement checks for potential errors during upload (e.g., network errors, permission issues). Use `try-except` blocks with informative error messages.\n","    - Progress Reporting: For large files, consider adding progress reporting mechanisms using third-party libraries or manual tracking.\n","    - Variable Naming: Use more descriptive variable names (e.g., `uploaded_file` instead of `downloaded`).\n","    - Type Annotations: Consider adding type annotations for clarity and potential type checking.\n","    - Folder Creation: Explore alternative methods like `Blob.make_dirs()`.\n","    - Logging: Use a logging library for structured logging instead of `print` statements.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 5);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["%run gdrive.py\n","\n","authenticate_google_drive() # gdrive.py\n"],"metadata":{"id":"7JcRoCPinNre"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mount_google_drive # gdrive.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"0f2oSUc9nNt3","executionInfo":{"status":"ok","timestamp":1712459968685,"user_tz":240,"elapsed":4,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"f8bfcbd4-f5d2-4a5f-eb25-cc85fb2745fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.mount_google_drive(mount_point: str = '/content/drive') -> None>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>mount_google_drive</b><br/>def mount_google_drive(mount_point: str=&#x27;/content/drive&#x27;) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/gdrive.py</a>Mounts Google Drive to the specified mount point.\n","\n","This function mounts the user&#x27;s Google Drive to the specified directory\n","within the Colab environment. This allows users to interact with their\n","Drive files directly through the file system.\n","\n","Args:\n","    mount_point (str, optional): The path to mount Google Drive. Defaults to &#x27;/content/drive&#x27;.\n","\n","Raises:\n","    RuntimeError: If there&#x27;s an error mounting the drive.\n","\n","Assumptions:\n","    - The user has already authenticated with Google Drive (using `authenticate_google_drive`).\n","    - The user has the necessary permissions to mount their Drive.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 35);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["download_file_from_drive # gdrive.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"fgs-aX-bnNwF","executionInfo":{"status":"ok","timestamp":1712459968685,"user_tz":240,"elapsed":3,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"0848d0a9-2808-4409-ade3-3c281c1a48f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.download_file_from_drive(drive_service: Any, file_id: str) -> _io.BytesIO>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>download_file_from_drive</b><br/>def download_file_from_drive(drive_service: Any, file_id: str) -&gt; io.BytesIO</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/gdrive.py</a>Downloads a file from Google Drive.\n","\n","This function downloads a specific file from the user&#x27;s Google Drive\n","given its ID. The downloaded content is returned as a BytesIO object.\n","\n","Args:\n","    drive_service (Any): The Google Drive service resource obtained using the `build` function.\n","    file_id (str): The ID of the file to download.\n","\n","Returns:\n","    io.BytesIO: The downloaded file content as a BytesIO object.\n","\n","Raises:\n","    Exception: If there&#x27;s an error downloading the file.\n","\n","Assumptions:\n","    - The user has already authenticated with Google Drive (using `authenticate_google_drive`).\n","    - The provided `drive_service` object is a valid Google Drive service resource.\n","    - The user has permission to access the file specified by `file_id`.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 62);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["upload_drive_file_to_cloud_storage # gdrive.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"k6AJCsabobxt","executionInfo":{"status":"ok","timestamp":1712459968958,"user_tz":240,"elapsed":276,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"5c022336-ac09-4a54-c992-e191d1c48fdc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.upload_drive_file_to_cloud_storage(bucket: google.cloud.storage.bucket.Bucket, folder_name: str, downloaded: _io.BytesIO, zip_file_name: str) -> google.cloud.storage.blob.Blob>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>upload_drive_file_to_cloud_storage</b><br/>def upload_drive_file_to_cloud_storage(bucket: storage.Bucket, folder_name: str, downloaded: io.BytesIO, zip_file_name: str) -&gt; storage.Blob</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/ingest.py</a>Uploads a file to Google Cloud Storage.\n","\n","This function uploads a file provided as a BytesIO object to a specified folder\n","within a Google Cloud Storage bucket with a conditional check.\n","\n","Args:\n","    bucket (storage.Bucket): The Google Cloud Storage bucket where the file will be uploaded.\n","    folder_name (str): The name of the folder within the bucket to upload the file to.\n","    downloaded (io.BytesIO): The BytesIO object containing the file data to upload.\n","    zip_file_name (str): The name of the file to be uploaded.\n","\n","Returns:\n","    storage.Blob: The uploaded blob object representing the uploaded file in Cloud Storage.\n","\n","Assumptions:\n","    - The user has authenticated with Google Cloud and has permission to access and write to the specified bucket.\n","    - The `downloaded` object is a valid BytesIO object containing the file data.\n","\n","Suggestions for Improvement:\n","    - Error Handling: Implement checks for potential errors during upload (e.g., network errors, permission issues). Use `try-except` blocks with informative error messages.\n","    - Progress Reporting: For large files, consider adding progress reporting mechanisms using third-party libraries or manual tracking.\n","    - Variable Naming: Use more descriptive variable names (e.g., `uploaded_file` instead of `downloaded`).\n","    - Type Annotations: Consider adding type annotations for clarity and potential type checking.\n","    - Folder Creation: Explore alternative methods like `Blob.make_dirs()`.\n","    - Logging: Use a logging library for structured logging instead of `print` statements.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 5);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["# Initialize a BytesIO object to hold downloaded file contents\n","downloaded: io.BytesIO = io.BytesIO()\n","\n","try:\n","    # Authenticate with Google Drive\n","    authenticate_google_drive()  # Presumably handles authentication\n","    drive_service: Any = build('drive', 'v3')  # Builds a Drive service object\n","\n","    # Access the Cloud Storage bucket\n","    bucket: storage.Bucket = storage.Client().bucket(BUCKET_NAME)  # References the desired bucket\n","\n","    # Download the file from Google Drive\n","    downloaded = download_file_from_drive(drive_service, FILE_ID)  # Downloads into the BytesIO object\n","\n","    # Type annotations for handling I/O (not affecting functionality)\n","    uploaded_blob: storage.Blob\n","    upload_bool: bool\n","\n","    # Check if the downloaded file has content\n","    if downloaded is None:\n","        print(\"Skipping upload and extraction as file already exists on cloud storage with matching size.\")\n","    else:\n","        # Proceed with upload and extraction only if the file has content\n","        uploaded_blob = upload_drive_file_to_cloud_storage(bucket, FOLDER_NAME, downloaded, ZIP_FILE_NAME)  # Uploads to Cloud Storage\n","\n","        # Decompress the ZIP file if it's a ZIP file\n","        if uploaded_blob.content_type == 'application/zip':\n","            json_file_name: str = extract_zip_file_conditionally(bucket, FOLDER_NAME, ZIP_FILE_NAME)  # Extracts conditionally\n","\n","    logging.info(\"File transfer successful!\")\n","\n","except Exception as e:\n","    logging.error(f\"An error occurred: {e}\")  # Catches and logs any errors\n","\n","finally:\n","    downloaded.close()  # Closes the downloaded file regardless of success or failure\n","    print(\"File transfer process completed.\")  # Indicates completion\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJVu6akdmXX_","executionInfo":{"status":"ok","timestamp":1712459983592,"user_tz":240,"elapsed":14910,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"2dcd1561-18ac-4ac5-f131-6b8ffd8a03fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading 100%\n","File 'tweets.json.zip' already exists on cloud storage with exact matching size, skipping upload.\n","File 'farmers-protest-tweets-2021-2-4.json' already exists on cloud storage with exact matching size, skipping extraction.\n","File transfer process completed.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Dh8NblbcCU8H"},"source":["## **BigQuery Storage Functions**\n","\n","**Functionality:**\n","\n","These Python functions interact with BigQuery to authenticate, create datasets and tables, and load data from Cloud Storage.\n","\n","**Key Concepts:**\n","\n","* **Client:** The `bigquery.Client` object is central to interacting with BigQuery.\n","* **Datasets and Tables:** Datasets organize tables, and both can be created or overwritten using these functions.\n","* **Data Loading:** Data is loaded from Cloud Storage in newline-delimited JSON format, and BigQuery automatically infers the schema.\n","* **Error Handling:** The functions use logging and try-except blocks to handle errors and provide informative messages.\n","\n","**Snippet 1: authenticate_bigquery**\n","\n","**Functionality:**\n","\n","Authenticates to BigQuery and returns a client object for subsequent operations.\n","\n","**Key Concepts:**\n","\n","* **Project ID:** Required for authentication.\n","\n","**Overall Assessment:**\n","\n","Clear and concise function for initial setup.\n","\n","**Potential Enhancements:**\n","\n","* **Error Handling:** Consider logging errors with more detail.\n","\n","**Snippet 2: create_dataset**\n","\n","**Functionality:**\n","\n","Creates a dataset if it doesn't exist or overwrites it if specified.\n","\n","**Key Concepts:**\n","\n","* **Mode:** Optional argument to control actions if the dataset already exists.\n","\n","**Overall Assessment:**\n","\n","Good flexibility with `mode` argument for handling existing datasets.\n","\n","**Potential Enhancements:**\n","\n","* **Input Validation:** Consider validating dataset names for compliance with BigQuery rules.\n","\n","**Snippet 3: create_table**\n","\n","**Functionality:**\n","\n","Creates a table within a dataset if it doesn't exist or overwrites it if specified.\n","\n","**Key Concepts:**\n","\n","* **Schema Inference:** Uses an empty schema to let BigQuery infer it from the data.\n","\n","**Overall Assessment:**\n","\n","Handles table creation effectively.\n","\n","**Potential Enhancements:**\n","\n","* **Schema Definition:** Explore allowing optional schema definition for more control.\n","\n","**Snippet 4: load_data_from_storage**\n","\n","**Functionality:**\n","\n","Loads data from a newline-delimited JSON file in Cloud Storage to a BigQuery table.\n","\n","**Key Concepts:**\n","\n","* **Load Job Configuration:** Specifies data format, schema inference, and handling of unknown values.\n","\n","**Overall Assessment:**\n","\n","Well-structured data loading process.\n","\n","**Potential Enhancements:**\n","\n","* **Progress Reporting:** Consider logging loading progress.\n","* **Data Validation:** Explore adding data validation checks before loading.\n"]},{"cell_type":"code","source":["%run storage.py\n","\n","authenticate_bigquery # storage.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"kLNuqnQMiv8n","executionInfo":{"status":"ok","timestamp":1712459983592,"user_tz":240,"elapsed":3,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"23f575bf-b989-4268-98e2-8b961f2ccae6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.authenticate_bigquery(project_id: str) -> google.cloud.bigquery.client.Client>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>authenticate_bigquery</b><br/>def authenticate_bigquery(project_id: str) -&gt; bigquery.Client</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/storage.py</a>Authenticates to BigQuery and returns the client object.\n","\n","Args:\n","    project_id (str): Your GCP project ID.\n","\n","Returns:\n","    bigquery.Client: The BigQuery client object for subsequent interactions.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 7);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["create_dataset # storage.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"zAPjRXySiv_e","executionInfo":{"status":"ok","timestamp":1712459983939,"user_tz":240,"elapsed":349,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"c580512a-6824-436b-ac3b-db1972a8994a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.create_dataset(client: google.cloud.bigquery.client.Client, dataset_name: str, mode: str = 'create') -> None>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>create_dataset</b><br/>def create_dataset(client: bigquery.Client, dataset_name: str, mode: str=&#x27;create&#x27;) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/storage.py</a>Creates a BigQuery dataset, handling existence checks and potential overwriting.\n","\n","Args:\n","    client (bigquery.Client): BigQuery client object.\n","    dataset_name (str): Name of the dataset to create.\n","    mode (Optional[str], optional): Action to take if the dataset already exists (&#x27;create&#x27; or &#x27;overwrite&#x27;). Defaults to &#x27;create&#x27;.\n","\n","Raises:\n","    Exception: For unexpected errors during dataset creation, existence check, or overwrite operation.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 30);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["create_table # storage.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"aObeNTAdiwCs","executionInfo":{"status":"ok","timestamp":1712459983939,"user_tz":240,"elapsed":5,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"0791be4c-3138-4ea3-f4ad-450e44c03b03"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.create_table(client: google.cloud.bigquery.client.Client, dataset_name: str, table_name: str, mode: str = 'create') -> None>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>create_table</b><br/>def create_table(client: bigquery.Client, dataset_name: str, table_name: str, mode: str=&#x27;create&#x27;) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/storage.py</a>Creates a BigQuery table, handling existence checks and potential overwriting.\n","Infers table schema from data upon creation.\n","\n","Args:\n","    client (bigquery.Client): BigQuery client object.\n","    dataset_name (str): Name of the dataset containing the table.\n","    table_name (str): Name of the table to create.\n","    mode (str, optional): Action to take if the table exists (&#x27;create&#x27; or &#x27;overwrite&#x27;). Defaults to &#x27;create&#x27;.\n","\n","Raises:\n","    Exception: For unexpected errors during table creation, existence check, or overwrite operation.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 70);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["load_data_from_storage # storage.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"znSn8XSEiwF7","executionInfo":{"status":"ok","timestamp":1712459983939,"user_tz":240,"elapsed":4,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"ab6a9bcb-c62a-4475-8b75-bb9a8d17e2d9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.load_data_from_storage(client: google.cloud.bigquery.client.Client, source_uri: str, dataset_name: str, table_name: str, json_file_name: str) -> None>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>load_data_from_storage</b><br/>def load_data_from_storage(client: bigquery.Client, source_uri: str, dataset_name: str, table_name: str, json_file_name: str) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/storage.py</a>Loads newline-delimited JSON data from Cloud Storage to a BigQuery table.\n","Infers table schema from data and ignores unknown values.\n","\n","Args:\n","    client (bigquery.Client): BigQuery client object.\n","    source_uri (str): URI of the data file in Cloud Storage (excluding the filename).\n","    dataset_name (str): Name of the dataset containing the table.\n","    table_name (str): Name of the table to load data into.\n","    json_file_name (str): Name of the JSON file in the bucket.\n","\n","Raises:\n","    Exception: For unexpected errors during data loading.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 119);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"teRz4l7jW-fq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712460005609,"user_tz":240,"elapsed":21674,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"295634c6-34cd-47e7-a692-4f1a421664ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwrite dataset tweets_dataset\n","Overwrite table tweets_dataset.tweets\n","Store gs://tw-gcp-public-lab/raw/farmers-protest-tweets-2021-2-4.json into BigQuery tweets_dataset.tweets\n","Data storage completed!\n"]}],"source":["# Authenticate to BigQuery\n","bigquery_client: bigquery.Client = authenticate_bigquery(PROJECT_ID)  # Authenticate and create a BigQuery client\n","\n","# Create dataset (overwrite if needed)\n","create_dataset(bigquery_client, DATASET_NAME, mode='overwrite')  # Create or overwrite the dataset\n","print(f\"Overwrite dataset {DATASET_NAME}\")  # Indicate dataset creation status\n","\n","# Create table (overwrite if needed)\n","create_table(bigquery_client, DATASET_NAME, TABLE_NAME, mode='overwrite')  # Create or overwrite the table\n","print(f\"Overwrite table {DATASET_NAME}.{TABLE_NAME}\")  # Indicate table creation status\n","\n","# Load data from Cloud Storage\n","load_data_from_storage(bigquery_client, GCS_SOURCE_URI, DATASET_NAME, TABLE_NAME, json_file_name)  # Load data from Storage\n","print(f\"Store {GCS_SOURCE_URI}{json_file_name} into BigQuery {DATASET_NAME}.{TABLE_NAME}\")  # Indicate loading status\n","\n","print(\"Data storage completed!\")  # Signal completion\n"]},{"cell_type":"markdown","metadata":{"id":"dEcJqRweD26B"},"source":["## **BigQuery Processing Functions**\n","\n","**Functionality:**\n","\n","- **Processes BigQuery Results:** The `process_bigquery_results` function executes the query, handles results, and converts them into a desired format (list of tuples with date and username).\n","\n","**Key Concepts:**\n","\n","- **Type Hints:** Employs type hints (`List`, `Tuple`, `datetime.date`) for improved code readability and potential static type checking.\n","- **Error Handling:** Incorporates `try-except` blocks to gracefully handle exceptions (`BadRequest` and generic exceptions).\n","- **Data Conversion:** Converts retrieved data rows into the specified format.\n","\n","**Overall Assessment:**\n","\n","- **Clear Separation:** Functions promote modularity and reusability.\n","- **Meaningful Variable Names:** Descriptive names enhance code understandability.\n","- **Error Management:** Handles potential errors during query execution and processing.\n","\n","**Potential Enhancements:**\n","\n","- **Input Validation:** Consider validating the constructed query string before execution.\n","- **Logging:** Integrate logging for detailed tracking and debugging.\n","- **Security:** Ensure secure credential management for BigQuery access.\n","- **Query Parameterization:** If DATASET_NAME and TABLE_NAME are not intended for hardcoding, utilize BigQuery's query parameters for better reusability and security.\n","- **Data Usage:** Currently, the extracted data is printed. You can modify this section to store the data in a desired location or perform further processing.\n","\n","This code provides a foundation for working with BigQuery data retrieval and processing. You can extend it based on your specific needs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLlwchwVZqYx","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1712460005610,"user_tz":240,"elapsed":4,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"48384cf7-ff00-4757-effb-f7e99d774f4d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.process_bigquery_results(client: google.cloud.bigquery.client.Client, query: str) -> List[Tuple[Any, Any]]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>process_bigquery_results</b><br/>def process_bigquery_results(client: bigquery.Client, query: str) -&gt; List[Tuple[Any, Any]]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/processing.py</a>Executes a BigQuery query, handles results, and performs data conversion.\n","\n","Args:\n","    client: BigQuery client object.\n","    query: BigQuery SQL query string.\n","\n","Returns:\n","    A list of tuples containing the extracted data (date and username).\n","\n","Raises:\n","    NotFound: If the query returns no results.\n","    Exception: For other unexpected errors during query execution or processing.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 5);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":59}],"source":["%run processing.py\n","\n","process_bigquery_results # processing.py\n"]},{"cell_type":"markdown","metadata":{"id":"5xm-D9ctF0Nx"},"source":["## **BigQuery Queries**\n","\n","**Snippet 1: Top 10 Dates with Top Users**\n","\n","**Functionality**\n","\n","This SQL query identifies the top 10 dates with the most tweets and, for each of those dates, finds the user with the most tweets (considering usernames alphabetically in case of ties).\n","\n","**Key Concepts**\n","\n","* **Common Table Expressions (CTEs):** The query utilizes two CTEs:\n","    * `TopDates`: Calculates the daily tweet count and ranks them in descending order, selecting the top 10.\n","    * `TopUsersDate`: Joins the `tweets` table with `TopDates` to find the user(s) with the most tweets for each top date. It uses `ROW_NUMBER()` to handle ties by username order.\n","* **Window Functions:** `ROW_NUMBER()` is used within `TopUsersDate` to assign a unique row number within each date partition, ordered by tweet count (descending) and then by number of tweets per user (descending).\n","* **Filtering:** The final result retrieves users with `row_number = 1` (the user with the most tweets for each date).\n","\n","**Overall Assessment**\n","\n","This query effectively addresses the task by leveraging CTEs for modularity and window functions to handle ranking and ties.\n","\n","**Potential Enhancements**\n","\n","* **Clarity:** Consider adding comments within the query to explain the purpose of each CTE.\n","* **Efficiency:** Explore alternative approaches to handle ties if performance is critical.\n","\n","**Data Usage**\n","\n","The query currently prints the `tweets_date` and `username`. You might want to consider storing this information in a table or using it for further analysis.\n","\n","**Snippet 2: Top 10 Most Used Emojis**\n","\n","**Functionality**\n","\n","This query extracts emojis from tweets and identifies the top 10 most frequently used emojis along with their counts.\n","\n","**Key Concepts**\n","\n","* **Regular Expressions (RegEx):** The `REGEXP_EXTRACT_ALL()` function utilizes a complex RegEx pattern to capture a wide range of emoji characters across different Unicode blocks.\n","* **UNNEST:** The `UNNEST()` operator is used to explode the extracted emoji list into a single row per emoji for counting.\n","\n","**Overall Assessment**\n","\n","This query effectively extracts and counts emojis, providing valuable insights into emoji usage.\n","\n","**Potential Enhancements**\n","\n","* **Filtering:** Depending on the analysis goals, you might want to filter out specific emoji categories (e.g., flags, country codes).\n","* **Normalization:** Consider normalizing emojis to a canonical form to handle variations (e.g., skin tone modifiers).\n","\n","**Data Usage**\n","\n","The query currently prints the `emoji` and `count`. You could store this information for further analysis of emoji popularity.\n","\n","**Snippet 3: Top 10 Influential Users**\n","\n","**Functionality**\n","\n","This query identifies the top 10 users with the most mentions (`@username`) received in tweets.\n","\n","**Key Concepts**\n","\n","* **UNNEST:** Similar to snippet 2, `UNNEST()` is used to explode the mentioned user list from each tweet for counting mentions.\n","\n","**Overall Assessment**\n","\n","This query effectively identifies influential users based on mentions.\n","\n","**Potential Enhancements**\n","\n","* **Filtering:** You might consider filtering out self-mentions or mentions from specific accounts.\n","* **Weighted Mentions:** Depending on the analysis goals, explore assigning weights to mentions based on factors like follower count.\n","\n","**Data Usage**\n","\n","The query currently prints the `username` and `mention_count`. You could store this information for further analysis of user influence."]},{"cell_type":"markdown","metadata":{"id":"kZOeNPrCbbU5"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kKjm82w1ES1F","executionInfo":{"status":"ok","timestamp":1712460005610,"user_tz":240,"elapsed":3,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"cd5d4dee-bf94-4f78-864e-d8685c6ec73f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.q1_time(client: google.cloud.bigquery.client.Client, query: str) -> List[Tuple[datetime.date, str]]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>q1_time</b><br/>def q1_time(client: bigquery.Client, query: str) -&gt; List[Tuple[datetime.date, str]]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/q1_time.py</a>Executes a BigQuery query, profiles its execution time line-by-line,\n","and returns extracted date-string pairs.\n","\n","Args:\n","    client: BigQuery client object.\n","    query: BigQuery SQL query string.\n","\n","Returns:\n","    List of tuples containing date-string pairs extracted from BigQuery results.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 8);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":60}],"source":["# Import project library (queries.py contains str queries)\n","import queries\n","\n","# q1_time.py defines the q1_time function\n","%run q1_time.py\n","\n","# Likely calls a function related to Query 1 execution time\n","q1_time\n"]},{"cell_type":"code","source":["# q2_time.py defines the q2_time function\n","%run q2_time.py\n","\n","q2_time\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"TEal5p7nBqv6","executionInfo":{"status":"ok","timestamp":1712460005977,"user_tz":240,"elapsed":369,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"a610bb6b-be3f-4521-f6fe-7ed52332f4fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.q2_time(client: google.cloud.bigquery.client.Client, query: str) -> List[Tuple[str, int]]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>q2_time</b><br/>def q2_time(client: bigquery.Client, query: str) -&gt; List[Tuple[str, int]]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/q2_time.py</a>Executes a BigQuery query, profiles its execution time line-by-line,\n","and returns extracted date-string pairs.\n","\n","Args:\n","    client: BigQuery client object.\n","    query: BigQuery SQL query string.\n","\n","Returns:\n","    List of tuples containing date-string pairs extracted from BigQuery results.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 7);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["# q3_time.py defines the q3_time function\n","%run q3_time.py\n","\n","q3_time\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"Qk22IpKEBqyk","executionInfo":{"status":"ok","timestamp":1712460005977,"user_tz":240,"elapsed":6,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"7bf7187d-892e-4290-fafa-9fd41cbbd5b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.q3_time(client: google.cloud.bigquery.client.Client, query: str) -> List[Tuple[str, int]]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>q3_time</b><br/>def q3_time(client: bigquery.Client, query: str) -&gt; List[Tuple[str, int]]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/q3_time.py</a>Executes a BigQuery query, profiles its execution time line-by-line,\n","and returns extracted date-string pairs.\n","\n","Args:\n","    client: BigQuery client object.\n","    query: BigQuery SQL query string.\n","\n","Returns:\n","    List of tuples containing date-string pairs extracted from BigQuery results.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 7);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["# q1_memory.py defines the q1_memory function\n","%run q1_memory.py\n","\n","q1_memory\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"ev8FT2deBq1H","executionInfo":{"status":"ok","timestamp":1712460005978,"user_tz":240,"elapsed":6,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"a6928847-fe3f-4287-c183-f8da0f1038bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.q1_memory(client: google.cloud.bigquery.client.Client, query: str) -> List[Tuple[datetime.date, str]]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>q1_memory</b><br/>def q1_memory(client: bigquery.Client, query: str) -&gt; List[Tuple[datetime.date, str]]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/q1_memory.py</a>Executes a BigQuery query, profiles its memory usage, and returns extracted date-string pairs.\n","\n","Args:\n","    client: BigQuery client object.\n","    query: BigQuery SQL query string.\n","\n","Returns:\n","    List of tuples containing date and string pairs extracted from BigQuery results.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 8);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["# q2_memory.py defines the q2_memory function\n","%run q2_memory.py\n","\n","q2_memory\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"JL8ig2r4Bq3u","executionInfo":{"status":"ok","timestamp":1712460005978,"user_tz":240,"elapsed":6,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"64b1e8c1-e5a7-4bd8-95f3-98ccb6831fbf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.q2_memory(client: google.cloud.bigquery.client.Client, query: str) -> List[Tuple[str, int]]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>q2_memory</b><br/>def q2_memory(client: bigquery.Client, query: str) -&gt; List[Tuple[str, int]]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/q2_memory.py</a>Executes a BigQuery query, profiles its memory usage, extracts string-integer pairs,\n","and handles potential conversion errors.\n","\n","Args:\n","    client: BigQuery client object.\n","    query: BigQuery SQL query string.\n","\n","Returns:\n","    List of tuples containing string-integer pairs extracted from BigQuery results.\n","    Returns an empty list if data conversion fails.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 7);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["# q3_memory.py defines the q3_memory function\n","%run q3_memory.py\n","\n","q3_memory\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"z4zkp360Bq6a","executionInfo":{"status":"ok","timestamp":1712460005978,"user_tz":240,"elapsed":5,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"564066cb-c88e-4fd6-8f25-1f87de07adb4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.q3_memory(client: google.cloud.bigquery.client.Client, query: str) -> List[Tuple[str, int]]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>q3_memory</b><br/>def q3_memory(client: bigquery.Client, query: str) -&gt; List[Tuple[str, int]]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/Othercomputers/My Mac/latam-challenge/src/q3_memory.py</a>Executes a BigQuery query, profiles its memory usage, extracts string-integer pairs,\n","and considers memory-efficient return strategies for large datasets.\n","\n","Args:\n","    client: BigQuery client object.\n","    query: BigQuery SQL query string.\n","\n","Returns:\n","    List of tuples containing string-integer pairs extracted from BigQuery results.\n","    Might suggest alternative return strategies (streaming or pagination) for large results.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 6);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["# Execute a script likely defining the q1_time function\n","%run q1_time.py\n","\n","print(\"LATAM Challenge Time - Top 10 Dates with more Tweets and the Username with more Tweets for each Day\")  # Print a title\n","\n","# Create a profiler instance\n","profiler = LineProfiler()\n","\n","# Add the q1_time function to be profiled\n","profiler.add_function(q1_time)\n","\n","# Enable profiling with a count-based approach\n","profiler.enable_by_count()\n","\n","# Call the q1_time function and capture its return value\n","q1_time_tuple = q1_time(bigquery_client, queries.top_dates_with_top_users)\n","\n","# Print the profiling statistics\n","profiler.print_stats()\n","\n","# Display the returned tuple\n","display(q1_time_tuple)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":731},"id":"zvJceQYCuH1e","executionInfo":{"status":"ok","timestamp":1712460007889,"user_tz":240,"elapsed":1916,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"71aa6017-0fe6-46a3-d26c-5f9bb1138ee7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LATAM Challenge Time - Top 10 Dates with more Tweets and the Username with more Tweets for each Day\n","Timer unit: 1e-09 s\n","\n","Total time: 1.65441 s\n","File: /content/drive/Othercomputers/My Mac/latam-challenge/src/q1_time.py\n","Function: q1_time at line 8\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","     8                                           @line_profiler.profile\n","     9                                           def q1_time(client: bigquery.Client, query: str) -> List[Tuple[datetime.date, str]]:\n","    10                                               \"\"\"\n","    11                                               Executes a BigQuery query, profiles its execution time line-by-line,\n","    12                                               and returns extracted date-string pairs.\n","    13                                           \n","    14                                               Args:\n","    15                                                   client: BigQuery client object.\n","    16                                                   query: BigQuery SQL query string.\n","    17                                           \n","    18                                               Returns:\n","    19                                                   List of tuples containing date-string pairs extracted from BigQuery results.\n","    20                                               \"\"\"\n","    21                                           \n","    22                                               # Delegate query execution and data extraction to the external function:\n","    23                                               # - Assumes 'process_bigquery_results' handles query execution, result processing,\n","    24                                               #   and extraction of date-string pairs.\n","    25                                               # - The decorator will profile the execution time of each line within this function,\n","    26                                               #   including the time spent within 'process_bigquery_results'.\n","    27         1 1654406819.0    2e+09    100.0      return process_bigquery_results(client, query)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n"," (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n"," (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n"," (datetime.date(2021, 2, 16), 'jot__b'),\n"," (datetime.date(2021, 2, 14), 'rebelpacifist'),\n"," (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n"," (datetime.date(2021, 2, 15), 'jot__b'),\n"," (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n"," (datetime.date(2021, 2, 23), 'Surrypuria'),\n"," (datetime.date(2021, 2, 19), 'Preetm91')]"]},"metadata":{}}]},{"cell_type":"code","source":["print(\"LATAM Challenge Time - Top 10 Dates Emojis\")  # Print a title\n","\n","# Create a profiler instance\n","profiler = LineProfiler()\n","\n","# Add the q2_time function to be profiled\n","profiler.add_function(q2_time)\n","\n","# Enable profiling with a count-based approach\n","profiler.enable_by_count()\n","\n","# Call the q2_time function and capture its return value\n","q2_time_tuple = q2_time(bigquery_client, queries.top_emojis)\n","\n","# Display the profiling statistics\n","profiler.print_stats()\n","\n","# Display the returned tuple\n","display(q2_time_tuple)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":731},"id":"l1c5mz74uH-J","executionInfo":{"status":"ok","timestamp":1712460009172,"user_tz":240,"elapsed":1285,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"27474335-6e03-4df4-c5e3-e0216c65a8ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LATAM Challenge Time - Top 10 Dates Emojis\n","Timer unit: 1e-09 s\n","\n","Total time: 1.10681 s\n","File: /content/drive/Othercomputers/My Mac/latam-challenge/src/q2_time.py\n","Function: q2_time at line 7\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","     7                                           @line_profiler.profile\n","     8                                           def q2_time(client: bigquery.Client, query: str) -> List[Tuple[str, int]]:\n","     9                                               \"\"\"\n","    10                                               Executes a BigQuery query, profiles its execution time line-by-line,\n","    11                                               and returns extracted date-string pairs.\n","    12                                           \n","    13                                               Args:\n","    14                                                   client: BigQuery client object.\n","    15                                                   query: BigQuery SQL query string.\n","    16                                           \n","    17                                               Returns:\n","    18                                                   List of tuples containing date-string pairs extracted from BigQuery results.\n","    19                                               \"\"\"\n","    20                                           \n","    21                                               # Delegate query execution and data extraction to the external function:\n","    22                                               # - Assumes 'process_bigquery_results' handles query execution, result processing,\n","    23                                               #   and extraction of date-string pairs.\n","    24                                               # - The decorator will profile the execution time of each line within this function,\n","    25                                               #   including the time spent within 'process_bigquery_results'.\n","    26         1 1106809844.0    1e+09    100.0      return process_bigquery_results(client, query)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["[('✊', 2402),\n"," ('❤️', 1382),\n"," ('❤', 397),\n"," ('☮️', 316),\n"," ('♂️', 179),\n"," ('✌️', 168),\n"," ('♀️', 148),\n"," ('✌', 106),\n"," ('‼️', 74),\n"," ('♥️', 73)]"]},"metadata":{}}]},{"cell_type":"code","source":["print(\"LATAM Challenge Time - Top 10 Influential Users\")  # Print a title\n","\n","# Create a profiler instance\n","profiler = LineProfiler()\n","\n","# Add the q3_time function to be profiled\n","profiler.add_function(q3_time)\n","\n","# Enable profiling with a count-based approach\n","profiler.enable_by_count()\n","\n","# Call the q3_time function and capture its return value\n","q3_time_tuple = q3_time(bigquery_client, queries.top_influential_users)\n","\n","# Display the profiling statistics\n","profiler.print_stats()\n","\n","# Display the returned tuple\n","display(q3_time_tuple)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":731},"id":"pSfoZ8C0uIE0","executionInfo":{"status":"ok","timestamp":1712461286898,"user_tz":240,"elapsed":1034,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"8863fcdd-2c36-4428-ad3f-07ccdd7a551f"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["LATAM Challenge Time - Top 10 Influential Users\n","Timer unit: 1e-09 s\n","\n","Total time: 1.00011 s\n","File: /content/drive/Othercomputers/My Mac/latam-challenge/src/q3_time.py\n","Function: q3_time at line 7\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","     7                                           @line_profiler.profile\n","     8                                           def q3_time(client: bigquery.Client, query: str) -> List[Tuple[str, int]]:\n","     9                                               \"\"\"\n","    10                                               Executes a BigQuery query, profiles its execution time line-by-line,\n","    11                                               and returns extracted date-string pairs.\n","    12                                           \n","    13                                               Args:\n","    14                                                   client: BigQuery client object.\n","    15                                                   query: BigQuery SQL query string.\n","    16                                           \n","    17                                               Returns:\n","    18                                                   List of tuples containing date-string pairs extracted from BigQuery results.\n","    19                                               \"\"\"\n","    20                                           \n","    21                                               # Delegate query execution and data extraction to the external function:\n","    22                                               # - Assumes 'process_bigquery_results' handles query execution, result processing,\n","    23                                               #   and extraction of date-string pairs.\n","    24                                               # - The decorator will profile the execution time of each line within this function,\n","    25                                               #   including the time spent within 'process_bigquery_results'.\n","    26         1 1000111227.0    1e+09    100.0      return process_bigquery_results(client, query)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["[('narendramodi', 2265),\n"," ('Kisanektamorcha', 1840),\n"," ('RakeshTikaitBKU', 1644),\n"," ('PMOIndia', 1427),\n"," ('RahulGandhi', 1146),\n"," ('GretaThunberg', 1048),\n"," ('RaviSinghKA', 1019),\n"," ('rihanna', 986),\n"," ('UNHumanRights', 962),\n"," ('meenaharris', 926)]"]},"metadata":{}}]},{"cell_type":"code","source":["# Workaround to stop memory profiler errors in the notebook\n","# Disables memory tracing\n","\n","# This line disables tracing memory allocations using the `sys` module.\n","# The `settrace` function sets a tracing function for Python. By setting it\n","# to `None`, any previously set tracing function (likely for memory profiling)\n","# is disabled. This can be useful to avoid errors caused by memory profiling\n","# tools within Jupyter Notebooks, but it also removes the ability to profile\n","# memory usage.\n","\n","# Consider alternative profiling approaches like `cProfile` or browser-based\n","# profiling tools that might be more compatible with Jupyter Notebooks.\n","# If possible, re-enable memory profiling after tests or when needed to\n","# analyze memory usage in your code.\n","\n","sys.settrace(None)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGTU-4ZASIC1","executionInfo":{"status":"ok","timestamp":1712460047109,"user_tz":240,"elapsed":254,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"e2e5b37a-44c3-4a61-e865-838cbf5093fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","PYDEV DEBUGGER WARNING:\n","sys.settrace() should not be used when the debugger is being used.\n","This may cause the debugger to stop working correctly.\n","If this is needed, please check: \n","http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n","to see how to restore the debug tracing back correctly.\n","Call Location:\n","  File \"<ipython-input-75-ca66abf563ff>\", line 16, in <cell line: 16>\n","    sys.settrace(None)\n","\n"]}]},{"cell_type":"code","source":["# Print a title describing the memory usage analysis\n","print(\"LATAM Challenge Memory - Top 10 Dates with more Tweets and the Username with more Tweets for each Day\")\n","\n","# Import libraries (assuming memory_profiler is available)\n","# Import on the right side\n","# ...\n","\n","# Measure memory usage of q1_memory function call\n","# This line uses the `memory_profiler` library (assuming it's imported)\n","# to measure the maximum memory usage of the `q1_memory` function call.\n","# It unpacks the function (`q1_memory`), arguments (`(bigquery_client, queries.top_dates_with_top_users)`),\n","# and keyword arguments (`{}`) into the `memory_usage` function.\n","# The `max_usage=True` argument specifies that we want to capture the peak memory usage.\n","\n","#memory_usage((q1_memory, (bigquery_client, queries.top_dates_with_top_users), {}), max_usage=True)\n","\n","# Possible improvements:\n","# - Consider capturing memory usage at different stages of the function\n","#   to identify potential memory bottlenecks.\n","# - Explore alternative memory profiling tools or libraries for more detailed insights.\n","q1_memory(bigquery_client, queries.top_dates_with_top_users)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kmxXSGImMVa","executionInfo":{"status":"ok","timestamp":1712460044329,"user_tz":240,"elapsed":1250,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"24065c77-496e-4e88-cc64-5cee62a0019f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LATAM Challenge Memory - Top 10 Dates with more Tweets and the Username with more Tweets for each Day\n","Filename: /content/drive/Othercomputers/My Mac/latam-challenge/src/q1_memory.py\n","\n","Line #    Mem usage    Increment  Occurrences   Line Contents\n","=============================================================\n","     8    204.7 MiB    204.7 MiB           1   @memory_profiler.profile\n","     9                                         def q1_memory(client: bigquery.Client, query: str) -> List[Tuple[datetime.date, str]]:\n","    10                                             \"\"\"\n","    11                                             Executes a BigQuery query, profiles its memory usage, and returns extracted date-string pairs.\n","    12                                         \n","    13                                             Args:\n","    14                                                 client: BigQuery client object.\n","    15                                                 query: BigQuery SQL query string.\n","    16                                         \n","    17                                             Returns:\n","    18                                                 List of tuples containing date and string pairs extracted from BigQuery results.\n","    19                                             \"\"\"\n","    20                                         \n","    21                                             # Delegate query execution and data extraction to the external function:\n","    22                                             # - Assumes 'process_bigquery_results' handles query execution, result processing,\n","    23                                             #   and extraction of date-string pairs.\n","    24    204.7 MiB      0.0 MiB           1       return process_bigquery_results(client, query)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n"," (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n"," (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n"," (datetime.date(2021, 2, 16), 'jot__b'),\n"," (datetime.date(2021, 2, 14), 'rebelpacifist'),\n"," (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n"," (datetime.date(2021, 2, 15), 'jot__b'),\n"," (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n"," (datetime.date(2021, 2, 23), 'Surrypuria'),\n"," (datetime.date(2021, 2, 19), 'Preetm91')]"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["# Print a title describing the memory usage analysis\n","print(\"LATAM Challenge Memory - Top 10 Dates Emojis\")\n","\n","# Import libraries (assuming memory_profiler is available)\n","# Import on the right side\n","# ...\n","\n","# Measure memory usage of q2_memory function call\n","# This line uses the `memory_profiler` library (assuming it's imported)\n","# to measure the maximum memory usage of the `q2_memory` function call.\n","# It unpacks the function (`q2_memory`), arguments (`(bigquery_client, queries.top_emojis)`),\n","# and keyword arguments (`{}`) into the `memory_usage` function.\n","# The `max_usage=True` argument specifies that we want to capture the peak memory usage.\n","\n","#memory_usage((q2_memory, (bigquery_client, queries.top_emojis), {}), max_usage=True)\n","\n","# Possible improvements:\n","# - If q2_memory logic significantly differs from q1_memory,\n","#   consider separate memory profiling for better understanding.\n","# - Explore alternative memory profiling tools or libraries for more detailed insights.\n","q2_memory(bigquery_client, queries.top_emojis)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O9x_6AOpwGzG","executionInfo":{"status":"ok","timestamp":1712460012645,"user_tz":240,"elapsed":1137,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"34b9edc8-4db5-4518-b76e-d97333c034e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LATAM Challenge Memory - Top 10 Dates Emojis\n","Filename: /content/drive/Othercomputers/My Mac/latam-challenge/src/q2_memory.py\n","\n","Line #    Mem usage    Increment  Occurrences   Line Contents\n","=============================================================\n","     7    204.7 MiB    204.7 MiB           1   @memory_profiler.profile\n","     8                                         def q2_memory(client: bigquery.Client, query: str) -> List[Tuple[str, int]]:\n","     9                                             \"\"\"\n","    10                                             Executes a BigQuery query, profiles its memory usage, extracts string-integer pairs,\n","    11                                             and handles potential conversion errors.\n","    12                                         \n","    13                                             Args:\n","    14                                                 client: BigQuery client object.\n","    15                                                 query: BigQuery SQL query string.\n","    16                                         \n","    17                                             Returns:\n","    18                                                 List of tuples containing string-integer pairs extracted from BigQuery results.\n","    19                                                 Returns an empty list if data conversion fails.\n","    20                                             \"\"\"\n","    21                                         \n","    22    204.7 MiB      0.0 MiB           1       try:\n","    23                                                 # Delegate query execution and data extraction to the external function:\n","    24    204.7 MiB      0.0 MiB           1           results = process_bigquery_results(client, query)\n","    25                                         \n","    26                                                 # Extract string-integer pairs, validating data format:\n","    27                                                 # - Assumes 'process_bigquery_results' returns a list of iterables with two elements.\n","    28                                                 # - Attempts to convert the second element of each row to an integer.\n","    29    204.7 MiB      0.0 MiB          13           return [(row[0], int(row[1])) for row in results]\n","    30                                         \n","    31                                             except ValueError as e:\n","    32                                                 # Handle potential errors during data conversion:\n","    33                                                 print(f\"Error converting data to string and integer pairs: {e}\")\n","    34                                                 return []  # Return an empty list to signal the error\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["[('✊', 2402),\n"," ('❤️', 1382),\n"," ('❤', 397),\n"," ('☮️', 316),\n"," ('♂️', 179),\n"," ('✌️', 168),\n"," ('♀️', 148),\n"," ('✌', 106),\n"," ('‼️', 74),\n"," ('♥️', 73)]"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["# Print a title describing the memory usage analysis\n","print(\"LATAM Challenge Memory - Top 10 Influential Users\")\n","\n","# Import libraries (assuming memory_profiler is available)\n","# Import on the right side\n","# ...\n","\n","# Measure memory usage of q3_memory function call\n","# This line uses the `memory_profiler` library (assuming it's imported)\n","# to measure the maximum memory usage of the `q3_memory` function call.\n","# It unpacks the function (`q3_memory`), arguments (`(bigquery_client, queries.top_influential_users)`),\n","# and keyword arguments (`{}`) into the `memory_usage` function.\n","# The `max_usage=True` argument specifies that we want to capture the peak memory usage.\n","\n","#memory_usage((q3_memory, (bigquery_client, queries.top_influential_users), {}), max_usage=True)\n","\n","# Possible improvements:\n","# - If q3_memory logic significantly differs from q1_memory and q2_memory,\n","#   consider separate memory profiling for better understanding.\n","# - Explore alternative memory profiling tools or libraries for more detailed insights.\n","# - Analyze the BigQuery query plan for `queries.top_influential_users` to identify\n","#   potential memory optimization opportunities within the query itself.\n","q3_memory(bigquery_client, queries.top_influential_users)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wulk-FtXwG1f","executionInfo":{"status":"ok","timestamp":1712460013661,"user_tz":240,"elapsed":1019,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"2e8c2f7f-5ba6-40a6-c6e1-ab3f465045ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LATAM Challenge Memory - Top 10 Influential Users\n","Filename: /content/drive/Othercomputers/My Mac/latam-challenge/src/q3_memory.py\n","\n","Line #    Mem usage    Increment  Occurrences   Line Contents\n","=============================================================\n","     6    204.7 MiB    204.7 MiB           1   @memory_profiler.profile  # Decorator to profile memory usage\n","     7                                         def q3_memory(client: bigquery.Client, query: str) -> List[Tuple[str, int]]:\n","     8                                            \"\"\"\n","     9                                            Executes a BigQuery query, profiles its memory usage, extracts string-integer pairs,\n","    10                                            and considers memory-efficient return strategies for large datasets.\n","    11                                         \n","    12                                            Args:\n","    13                                                client: BigQuery client object.\n","    14                                                query: BigQuery SQL query string.\n","    15                                         \n","    16                                            Returns:\n","    17                                                List of tuples containing string-integer pairs extracted from BigQuery results.\n","    18                                                Might suggest alternative return strategies (streaming or pagination) for large results.\n","    19                                            \"\"\"\n","    20                                         \n","    21    204.7 MiB      0.0 MiB           1      try:\n","    22                                                # Delegate query execution and data extraction to the external function:\n","    23    204.7 MiB      0.0 MiB           1          results = process_bigquery_results(client, query)\n","    24                                         \n","    25                                                # Extract string-integer pairs, validating data format:\n","    26    204.7 MiB      0.0 MiB          13          formatted_results = [(row[0], int(row[1])) for row in results]\n","    27                                         \n","    28                                                # Consider memory-efficient return strategies based on result size:\n","    29    204.7 MiB      0.0 MiB           1          if len(formatted_results) > 1000:  # Adjust threshold as needed\n","    30                                                    print(\"Warning: Returning a large dataset. Consider using streaming or pagination for memory optimization.\")\n","    31                                                    # Potentially explore implementation of streaming or pagination techniques here\n","    32                                         \n","    33    204.7 MiB      0.0 MiB           1          return formatted_results\n","    34                                         \n","    35                                            except ValueError as e:\n","    36                                                print(f\"Error converting data to string and integer pairs: {e}\")\n","    37                                                return []  # Return an empty list to signal the error\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["[('narendramodi', 2265),\n"," ('Kisanektamorcha', 1840),\n"," ('RakeshTikaitBKU', 1644),\n"," ('PMOIndia', 1427),\n"," ('RahulGandhi', 1146),\n"," ('GretaThunberg', 1048),\n"," ('RaviSinghKA', 1019),\n"," ('rihanna', 986),\n"," ('UNHumanRights', 962),\n"," ('meenaharris', 926)]"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kb9SWakoNiJe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712460013661,"user_tz":240,"elapsed":2,"user":{"displayName":"Juan Herrera","userId":"01250943537373452870"}},"outputId":"6e25865d-2794-413c-f6f4-f4e9c1224f00"},"outputs":[{"output_type":"stream","name":"stdout","text":["The notebook execution ended\n","Elapsed time in the notebook: 55.36 seconds\n"]}],"source":["# Check if end_time variable has already been assigned a value\n","if end_time is not None:\n","    # The code has already captured the end time\n","    print(\"The notebook execution already ended\")\n","else:\n","    # The end time hasn't been recorded yet, so measure and store it\n","    print(\"The notebook execution ended\")\n","    end_time = measure_notebook_elapsed_time(float(START_TIME))\n","\n","# Print the total elapsed time using the captured end_time\n","print_notebook_elapsed_time(end_time)  # Print the result\n","\n","# Assumptions:\n","# - This code assumes `end_time` is a variable used to store the notebook's end time.\n","# - It also assumes `measure_notebook_elapsed_time` is a function that calculates elapsed time\n","#   based on a reference time point (likely `START_TIME`).\n","# - `print_notebook_elapsed_time` is assumed to be a function that displays the elapsed time\n","#   in a human-readable format, likely using `end_time`.\n","\n","# Possible improvements:\n","# - Consider error handling for cases where `START_TIME` cannot be converted to a float.\n","# - Explore alternative libraries or methods for more precise or detailed time measurements.\n"]},{"cell_type":"markdown","source":["# **End of Challenge Code**"],"metadata":{"id":"RuwwnEtf_OFV"}},{"cell_type":"markdown","source":["# **Observations for Queries from ChatGPT**\n","\n","Your queries (queries.py) are well-structured and easy to understand. Here are some observations and suggestions:\n","\n","- Top Dates with Top Users: This query seems to work well, but keep in mind that if there's a tie in the number of tweets on a day and two users have the same number of tweets on that day, the user whose username comes first alphabetically will be selected. This may not be ideal if there are many users with the same number of tweets on a day. You might consider other strategies for handling ties, such as randomly selecting among the users in case of a tie.\n"," - Yes this was handled considering alphabetic order\n","- Top Emojis: The regular expression used to extract emojis seems well-constructed and covers a wide range of emojis. However, note that some text processing libraries, such as spaCy, may offer more advanced functionalities for handling emojis and other special characters.\n"," - Interesting, will investigate **spaCy**\n","- Top Influential Users: This query appears to be well-formulated and should return the top 10 most influential users based on the count of mentions received.\n"," - No feedback for this\n","\n","Overall, your queries are clear and well-documented, which is excellent for ease of understanding and maintenance. If you need any further assistance with these queries or any other aspect of your project, feel free to ask!"],"metadata":{"id":"A7QZZanr1t9G"}},{"cell_type":"markdown","source":["## **Notes**\n","\n","### Reflection and Continuous Improvement\n","\n","**Release:**\n","\n","* \"Release\" is used for final testing before releasing a version to \"main\". I used it 3 times at the beginning.\n","* Gitflow makes using Git easier by saving commands.\n","* **Be careful with the commit text:**\n","    * The \"ammend\" command generates a \"force push\" and 2) does not work as it should.\n","    * Make sure the branch is not deleted in the PR.\n","    * Gitflow deletes it by default when closing the flow. I configured it not to.\n","    * Renaming a branch also deletes it.\n","* **Always do \"pull\" before working!**\n","* **It is better to make a pull request for a single commit.**\n","* At first I used Gitflow practices without Gitflow, but then I started using it completely.\n","* Gitflow is simpler to use, but the branch naming conventions were difficult for me (e.g. \"feature_ignore\" vs \"feature/ignore\").\n","* **Releases generate a \"release tag\" and homologate both \"develop\" and \"main\".**\n","* I hesitated between using English or Spanish, but I understand that English is better for universality, consistency, conventions and compatibility with tracking tools.\n","* I had to figure out how to respond to both Gitflow and pull requests. I mixed Gitflow, Github Desktop, Github's graphical interface and Visual Studio Code to achieve this.\n","* It took me time to achieve a uniform and constant rhythm through the branches and progress. I learned to start all features first, then upload all PRs and finally approve them all. I think this would work well if I'm working in a team, as I've checked that no errors occur.\n","* I experienced minor divergence conflicts between the origin and local branches, this is avoided by following the steps learned throughout this challenge.\n","* **Hotfix is dangerous because it makes changes directly to \"main\". I tried it and prefer to avoid it.**\n","* I experienced a major conflict with merge mixes in different branches due to not following a logical order of steps when there are multiple local changes. For the sake of time, I had to forcefully solve it by approving a pull request that authorized the emergency merge. This was similar to a hotfix but since I didn't understand the concept well. When I detected this situation I had to make a backup immediately, as well as save the files that Visual Studio Code keeps temporarily even if they are deleted. Finally I solved it and renamed the branches with “revert” and “merge” to follow the hotfix nomenclature.\n","\n","**Thoughts on Scala:**\n","\n","* It is important to handle inputs and outputs correctly, so I used type annotations to control IOs mostly.\n","* Documentation, clean code, assumptions, error handling, edge cases and tests. I gave Gemini the context in the readme to generate assessments and documentation of my code.\n","\n","**Mistakes:**\n","\n","* Initially I focused on getting the code working and then organizing it into separate files. This was a mistake. I should have done it from the start, as it improves organization, readability, maintenance, modularity and benefits teamwork.\n","* **Learning:**\n","    * I still have a lot to learn and if I do well, I should make sure to absorb all the GIT practices I can learn from the experience with other people.\n","    * This challenge was a great challenge for me, as I had no experience with GCP. My strength is Spark and Databricks, which is much simpler to use. However, I focused on achieving this challenge with Google Cloud Storage and BigQuery.\n","    * In the end, I ran everything to verify that it works well. However, and therefore, I didn't realize that when I commented my code using Gemini's help, it changed the outputs of some of my definitions. I was always careful because I noticed it several times. In fact, I asked it not to do it. But I must be more careful and do thorough reviews before moving on to final steps in the main branches. I just checked everything focusing on outputs to check that everything is working well.\n","\n","### Configurations\n","\n","* **To only merge in \"dev\" in releases and thus go through pull request in \"main\":**\n","\n","```\n","git config gitflow.release.finish.merge 0\n","```\n","\n","* **To prevent development branches from being deleted on the origin:**\n","\n","```\n","git config gitflow.feature.finish.keepremote=true\n","git config --global gitflow.release.keepremote true\n","```\n","\n","### Features\n","\n","* **To start a feature:**\n","\n","```\n","git flow feature start feature\n","git checkout -b feature/\n","```\n","\n","* **Commits and PR in \"develop\" branch:**\n","\n","```\n","feat: …\n","Detail\n","```\n","\n","* **To finish a feature:**\n","\n","```\n","git flow feature finish feature\n","restore branch in PR\n","```\n","\n","### Releases (caution)\n","\n","* **Full preventive pull:**\n","\n","```\n","git pull --all\n","```\n","\n","* **To start a release:**\n","\n","```\n","git flow release start v0.0.\n","git push origin release/v0.0.\n","git log --oneline > changelog.txt\n","```\n","\n","* **In Github:**\n","\n","```\n","rel: …\n","Detail\n","```\n","\n","* **PR in \"develop\" branch:**\n","\n","```\n","git flow release finish 'v0.0.2' (this generates the tag)\n","tag description: “Version 0.0.2\n","```\n","\n","### Hotfixes (caution)\n","\n","* **To start a hotfix:**\n","\n","```\n","git flow hotfix start reload\n","```\n","\n","* **Commits and PR in \"main\" branch:**\n","\n","```\n","hotfix: Fix…\n","Detail\n","```\n","\n","* **To finish a hotfix:**\n","\n","```\n","git flow hotfix finish reload\n","tag description: hotfix/v0.0.2\n","```\n","\n","**Important:** Use hotfixes sparingly and only for critical issues in the production environment.\n","\n","### Useful Commands\n","\n","* To initialize a Gitflow workflow:\n","\n","```\n","git flow init\n","```\n","\n","* To delete a tag:\n","\n","```\n","git tag -d 0.0.1\n","```\n","\n","* To list tags:\n","\n","```\n","git tag --list\n","```\n","\n","* To list branches (local and remote):\n","\n","```\n","git branch -a\n","```\n","\n","* To delete a local branch:\n","\n","```\n","git branch -D release/0.0.1\n","```\n","\n","* To abort a release (avoid if possible):\n","\n","```\n","git flow release delete -f v0.0.3\n","```\n","\n","* To show Gitflow configuration:\n","\n","```\n","git config --get-regexp '^gitflow\\..*'\n","```\n","\n","* To delete Gitflow configuration:\n","\n","```\n","git config --unset gitflow.feature.finish.keep\n","```\n","\n","* To pull all remote branches into your local repository:\n","\n","```\n","git pull --all\n","```\n","\n","### Skills\n","\n","* Acheived\n"," * Release process\n"," * Postman POST request preparation\n"," * Unit tests\n"," * Clean code\n"," * Documentation\n"," * IA support: Gemini (focused on Google) and ChatGPT (for coding)\n"," * Self and third assumptions\n"," * Avoid unnecessary disk/memory/cpu processing\n"," * I/O\n"," * Google Cloud (Storage, BigQuery, IAM)\n"," * CTE and SQL (RegExp, Unnest)\n"," * GIT skills (good practices and git flow practices)\n","   * git-flow\n","   * git practices\n","   * git network\n","   * pull requests\n","   * hotfix\n","   * release\n","   * feature\n","   * git commands\n","\n","* Partially achieved\n"," * Logging to Python files (there are various py files without logging)\n"," * File organization (acheived at the end instead of the beginning. Besides, I miss a better folder structure for the project)\n"," * TDD (I didn't save my tests in Google Colab Notebook, that is how I acheived the code as it was new technologies for me, my strength was with Spark and Databricks)\n"," * Error handling (I tried to consider error handling and board cases. Focusing especifically in inputs and outputs)\n"," * Type Annotations (This was very helpful for me to understand what type of data I receive or return, very useful for understanding how Google Cloud libraries work. I had to look at the code of a couple of them to understand them.)\n"," * Functional Programming (First-class functions, pure functions, and function composition. I am interested in learning Cats for Scala.)\n"," * Decorators\n"," * Time and memory measurement\n","\n","* Not acheived\n"," * Documented Improvements (There is a lot that can be improved but I did my best)\n"," * GitHub Actions (I am really interested on this to automate the manual jobs that I had to do on this challenge)\n"," * Unit Test (I didn't have the time to test with unit tests in my IDE, I only created them with some tests to see if I tested well my code when developing)\n","\n","### Insights from ChatGPT\n","In your code, you've incorporated several practices and techniques related to Python programming and interaction with the Google Cloud Platform:\n","\n","1. **Logging:** Utilizing the `logging` module to record events and informative messages throughout function execution.\n","\n","2. **Type Annotations:** Employing type hints (`typing`) to specify parameter and return value types in functions, enhancing code readability and error detection.\n","\n","3. **Exception Handling:** Implementing error management to address potential issues during authentication, dataset and table creation, and data loading to BigQuery, enhancing code robustness.\n","\n","4. **Google Cloud API Usage:** Interacting with the BigQuery API within the Google Cloud Platform to execute operations like authentication, dataset and table creation, and data loading.\n","\n","5. **Functional Programming:** While not explicitly applying functional programming design patterns, you adhere to certain functional programming principles by treating functions as first-class citizens and maintaining purity by minimizing side effects.\n","\n","6. **Dependency Injection:** Passing the BigQuery client as a parameter to functions requiring it, following the dependency injection principle, thereby promoting modularity and code reusability.\n","\n","7. **Adherence to Good Development Practices:** Demonstrating good practices such as using descriptive function and variable names, implementing explicit error handling, and organizing code into specialized functions.\n","\n","In summary, your code exhibits a structured and meticulous approach to interfacing with the BigQuery API, leveraging Python-specific features and adhering to sound development principles.\n","\n","**Areas of improvement:**\n","Here are some areas where you could consider improvements or refinements in your code:\n","\n","1. **Error Handling:** While you have implemented error handling, consider adding more specific error messages or logging details to aid in troubleshooting.\n","\n","2. **Unit Testing:** You've mentioned an interest in unit testing; consider implementing unit tests for your functions to ensure their correctness and robustness.\n","\n","3. **Code Duplication:** There are some repetitive patterns in your code, such as logging messages and dataset/table existence checks. Consider refactoring these into reusable functions or decorators to adhere more closely to the DRY (Don't Repeat Yourself) principle.\n","\n","4. **Function Size:** Some of your functions could be broken down into smaller, more focused functions. This can improve readability and maintainability.\n","\n","5. **Documentation:** While you have docstrings for your functions, consider adding more detailed explanations, especially regarding the purpose and behavior of each function.\n","\n","6. **Configuration Management:** Externalize configuration settings (e.g., project ID, dataset names) to separate configuration files or environment variables for better manageability.\n","\n","7. **Consistent Logging:** Ensure consistency in logging levels and messages throughout your codebase for easier debugging and monitoring.\n","\n","8. **Data Validation:** Consider adding more robust data validation, especially when loading data from external sources, to ensure data integrity and prevent potential issues.\n","\n","9. **Code Comments:** While your code is generally well-structured and readable, adding comments to explain complex logic or decision-making processes can further improve readability for others (and your future self).\n","\n","10. **Security Considerations:** Ensure that your code follows best practices for handling sensitive information, such as project IDs and authentication credentials, to prevent accidental exposure.\n","\n","By addressing these areas, you can enhance the readability, maintainability, and reliability of your codebase.\n","\n","### Insights from Gemini\n","Based on the code snippets you've shown, here's what I can glean about your potential programming interests and skills:\n","\n","**Areas of Interest:**\n","\n","- **Python:** You seem comfortable working with Python code, utilizing functions, type hints, docstrings, and iterating through data structures.\n","- **Clean Code Principles:** You're interested in writing clean and well-structured code, as evidenced by your desire to improve code readability and maintainability.\n","- **Data Analysis:** The `q1_time` function suggests you might be working with BigQuery for data analysis tasks.\n","- **Environment Variables:** The code snippet using `os.environ` indicates an interest in accessing and potentially using system environment variables.\n","- **Time Measurement:** The `measure_elapsed_time` function demonstrates an understanding of measuring elapsed time in Python.\n","\n","**Overall Skills:**\n","\n","- **Code Comprehension:** You can effectively understand and explain the purpose and functionality of code snippets.\n","- **Code Improvement:** You're interested in applying clean code principles to improve code quality.\n","- **Problem-Solving:** You can break down code into its components and analyze its functionality.\n","\n","**Additional Considerations:**\n","\n","- The specific details of the code snippets (like `q1_time`) might hint at a larger project you're working on, but without more context, it's difficult to say for sure.\n","- The lack of code execution (due to my safety restrictions) prevents me from observing how the code interacts with external systems or libraries.\n","\n","**Areas for Improvement:**\n","\n","## Areas for Improvement Based on Your Code:\n","\n","**1. Handling Errors and Exceptions:**\n","\n","- While the `q1_time` function includes basic error handling with `try...except`, consider being more specific about the exceptions you might encounter (e.g., `bigquery.QueryJobClientError`). This allows for more tailored error messages and handling.\n","\n","**2. Testing:**\n","\n","The provided snippets don't explicitly show unit tests. Implementing unit tests for your functions would ensure their correctness and reliability as your code evolves.\n","\n","**3. Logging:**\n","\n","While the code prints information to the console, consider using a proper logging library like `logging` for a more structured and centralized approach. This helps track code execution and identify potential issues more easily.\n","\n","**4. Modularity:**\n","\n","The `q1_time` function is a good example of modularity. Explore further opportunities to break down larger code blocks into smaller, reusable functions with clear responsibilities.\n","\n","**5. Readability:**\n","\n","- **Variable Names:** While variable names like `key` and `value` are generally understandable, consider using more descriptive names when appropriate. For example, in `q1_time`, `date_field` and `string_field` could be more specific based on the actual data.\n","- **Comments:** Add comments to explain complex logic or non-obvious parts of the code, especially when dealing with external libraries or specific data structures.\n","\n","**6. Specific Libraries/Frameworks:**\n","\n","- The `q1_time` function utilizes the BigQuery client library. Consider exploring more advanced features of the library for data manipulation or transformation within BigQuery itself (if needed).\n","\n","**Additional Tips:**\n","\n","- **Code Formatting:** Consistent code formatting using tools like `autopep8` improves readability.\n","- **Static Code Analysis:** Utilize static code analysis tools like `pylint` or `mypy` to identify potential issues early on.\n","\n","Remember, clean code is an ongoing process. By continuously striving for improvement in these areas, you'll write code that is not only functional but also maintainable, readable, and robust."],"metadata":{"id":"IgMdsORgut7Y"}},{"cell_type":"markdown","source":[],"metadata":{"id":"-hvMq9cTNN9w"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}